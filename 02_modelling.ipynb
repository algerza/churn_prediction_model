{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, f1_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data (cleaning and outlier techniques applied)\n",
    "df = pd.read_csv('churn_cleaned_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column and save it to a variable\n",
    "#   If you need to bring the column back later, simply reassign it to the DataFrame\n",
    "#   df['customerID'] = customer_id\n",
    "customer_id = df.pop('customerID')\n",
    "\n",
    "# Separate the target variable (Churn) from the rest of the dataset\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing our training dataset\n",
    "Given that our dataset is imbalanced (26.5% of the users churn), we need to correct this effect in order to obtain the desired results with the model.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a popular algorithm used for data upsampling in machine learning. It creates synthetic samples of the minority class by creating new observations that are similar to existing observations, thus balancing the class distribution. We can perform data upsampling using SMOTE in Python with the imbalanced-learn library.\n",
    "\n",
    "Balancing your dataset with SMOTE should be performed on the training set only. This way, you ensure that your model learns from a balanced representation of the data while preserving the integrity and independence of the test and validation datasets. In other words, you avoid information leakage, realistic representation of the data and an independent evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SMOTE object\n",
    "oversample = SMOTE()\n",
    "\n",
    "# Apply SMOTE to upsample the minority class (Churn = 1) on the training set only\n",
    "X_resampled_train, y_resampled_train = oversample.fit_resample(X, y)\n",
    "\n",
    "# Combine the resampled features and target variable into a new training DataFrame\n",
    "resampled_df_train = pd.concat([X_resampled_train, y_resampled_train], axis=1)\n",
    "\n",
    "# Calculate the churn and non-churn counts\n",
    "churn_count = resampled_df_train[resampled_df_train['Churn'] == 1].shape[0]\n",
    "non_churn_count = resampled_df_train[resampled_df_train['Churn'] == 0].shape[0]\n",
    "\n",
    "# Set up the plot size and title\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Churn Rate')\n",
    "\n",
    "# Set the colors for the pie chart sections\n",
    "colors = ['lightcoral', 'lightgreen']\n",
    "\n",
    "# Create the pie chart\n",
    "plt.pie([churn_count, non_churn_count], labels=['Churn', 'Non-Churn'], autopct='%1.1f%%', colors=colors)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset\n",
    "Divide the dataset into training, validation, and test sets. The typical split is 70-80% for training, 10-15% for validation, and 10-15% for testing. The validation set helps in model selection and hyperparameter tuning.\n",
    "\n",
    "Therefore, in order to obtain a split of 70% for training, 15% for validation, and 15% for testing we are setting the test dataset with a size of 15% of the original dataset, while the combined training/validation set is split with a test size of 0.1765 (approximately 15% of the combined training/validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign to variables \n",
    "X, y = X_resampled_train, y_resampled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "We are exploring different options for our churn prediction, from more simple and interpretable models (i.e. Logistic Regression) to advanced models (i.e. SVM or XGBoost). We will decide which one to pick based on the validation set's performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of models including additional choices\n",
    "models = [\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(probability=True),\n",
    "    XGBClassifier(),\n",
    "    MLPClassifier(max_iter=1000)\n",
    "]\n",
    "\n",
    "# Iterate over the models\n",
    "for model in models:\n",
    "    # Train the model on the resampled training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "\n",
    "    # Calculate prediction probabilities on the validation set\n",
    "    y_prob_val = model.predict_proba(X_val)[:, 1] # Probability of the positive class (churn)\n",
    "\n",
    "    # Evaluate the model performance on the validation set\n",
    "    accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "    recall_val = recall_score(y_val, y_pred_val)\n",
    "    precision_val = precision_score(y_val, y_pred_val)\n",
    "    f1_val = f1_score(y_val, y_pred_val)\n",
    "    cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "    tn_val, fp_val, fn_val, tp_val = cm_val.ravel()\n",
    "    specificity_val = tn_val / (tn_val + fp_val)\n",
    "\n",
    "    # Print evaluation metrics on the validation set for each model\n",
    "    print(f\"Model: {type(model).__name__}\")\n",
    "    print(\"Model classification report\")\n",
    "    print(f\"Accuracy: {accuracy_val:.4f}\")\n",
    "    print(f\"Recall: {recall_val:.4f}\")\n",
    "    print(f\"Precision: {precision_val:.4f}\")\n",
    "    print(f\"F1 Score: {f1_val:.4f}\")\n",
    "    print(f\"Confusion Matrix: \\n{cm_val}\")\n",
    "    print(f\"Specificity: {specificity_val:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost (Extreme Gradient Boosting) shows a slightly higher F1 score compared to other models like Logistic Regression. It is often a popular choice for many data science projects because it offers high performance and efficiency with parallel processing and tree pruning. Moreover it provides built-in regularization and handles missing values, making it versatile for regression and classification tasks. XGBoost's ensemble method yields accurate predictions, and its feature importance analysis aids in understanding data patterns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "Properly tuning these hyperparameters can significantly improve the model's accuracy, prevent overfitting, and ensure optimal performance on unseen data. Without effective hyperparameter tuning, the model may underperform, leading to suboptimal results and wasted computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBoost classifier object\n",
    "xgb_clf = XGBClassifier()\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object with the classifier, hyperparameter grid, and evaluation metric\n",
    "grid_search = GridSearchCV(xgb_clf, param_grid, scoring='f1', cv=5)\n",
    "\n",
    "# Fit the GridSearchCV on the validation data\n",
    "grid_search.fit(X_val, y_val)\n",
    "\n",
    "# Get the best hyperparameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating our tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new XGBoost classifier with the best hyperparameters\n",
    "best_xgb_clf = XGBClassifier(**best_params)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "best_xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = best_xgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "recall_test = recall_score(y_test, y_pred_test)\n",
    "precision_test = precision_score(y_test, y_pred_test)\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "tn_test, fp_test, fn_test, tp_test = cm_test.ravel()\n",
    "specificity_test = tn_test / (tn_test + fp_test)\n",
    "\n",
    "# Print evaluation metrics on the test set\n",
    "print(\"\\nTest classification report\")\n",
    "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Recall: {recall_test:.4f}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"F1 Score: {f1_test:.4f}\")\n",
    "print(f\"Confusion Matrix: \\n{cm_test}\")\n",
    "print(f\"Specificity: {specificity_test:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning our XGBoost model we can determine that:\n",
    "- Our model achieved an accuracy of 85.25% on the test data, meaning that 85.25% of the customers were correctly classified as churn or non-churn users.\n",
    "\n",
    "- The recall, which measures our ability to identify churn users accurately, was at an impressive 88.02%. This indicates that we correctly identified 88.02% of the customers who were likely to churn, which is crucial for focusing our retention efforts on those at risk.\n",
    "\n",
    "- The precision, representing our accuracy in predicting churn correctly, stood at 83.39%. This means that when we predict a customer will churn, we can be confident that around 83.39% of the time, our prediction is accurate.\n",
    "\n",
    "- The F1 score, which balances precision and recall, was at 85.64%. This shows that our model has a good balance between accurately predicting churn and identifying most of the actual churners. \n",
    "\n",
    "- However specificity decreased compared to our initial model, showing that our hypertuned model shows a worse performance identifying non-churn users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with test labels and our predictions\n",
    "final_df = pd.DataFrame({'prediction_churn': y_pred_test, 'is_churn': y_test})\n",
    "\n",
    "# Calculate percentage of churned users we predicted to be churn\n",
    "#  We arrive at the same figure as Recall\n",
    "final_df[(final_df['is_churn']==1) & (final_df['prediction_churn']==1)].shape[0] / final_df[final_df['is_churn']==1].shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model interpretability\n",
    "Model interpretability is important for building trust between stakeholders, understanding model behavior, identifying and resolving errors, ensuring regulatory compliance, facilitating collaboration, and guiding model improvement. It plays a critical role in the practical application of machine learning models and enables their effective and responsible use in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an explainer object by providing our XGBoost model,\n",
    "explainer = shap.Explainer(best_xgb_clf)\n",
    "\n",
    "# Calculate SHAP value using our testing set\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Create a summary plot\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How should you interpret it?\n",
    "MonthlyCharges being blue on the left and red on the right, it means that low values of MonthlyCharges have a negative impact on the predicted target value, whereas high values of MonthlyCharges have a positive impact to the output.\n",
    "\n",
    "Similarly, with tenure being blue on the right and red on the left, it means that low values of tenure have a positive impact on the predicted target value, whereas high values of tenure have a negative impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values, max_display=15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, these results suggest that pricing plans, contract terms and how long are customers engaged with the company (tenure) are important factors in predicting customer churn. The model may be used to optimize pricing plans and contract terms to minimize churn and maximize customer retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forceplot for first observation\n",
    "shap.initjs()\n",
    "shap.plots.force(shap_values[38]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the SHAP values in a different format\n",
    "shap.plots.waterfall(shap_values[38])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the trained model\n",
    "Storing the model locally provides convenience, reproducibility, deployment flexibility, and collaboration capabilities. It allows you to leverage the trained model for making predictions, sharing, and working on further improvements without the need for retraining or relying on the original training data.\n",
    "\n",
    "We will be using `joblib`, a Python library that provides tools for efficient and easy serialization (saving) and deserialization (loading) of Python objects. It is primarily used for handling large data structures, such as NumPy arrays or scikit-learn models, in a way that minimizes memory usage and serialization time. It provides improved efficiency, memory management, and parallel processing capabilities compared to the standard pickle module. Another alternative would be storing the model using `pickle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "model_dump = 'churn_prediction_xgboost_model.joblib'\n",
    "joblib.dump(model, model_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from file\n",
    "loaded_model = joblib.load('churn_prediction_xgboost_model.joblib')\n",
    "\n",
    "# Read one row of data for demonstration purposes\n",
    "X_new = pd.read_csv('churn_cleaned_df.csv').tail(1)\n",
    "X_new = X_new.drop(['Churn', 'customerID'], axis=1)\n",
    "\n",
    "# Use the loaded model for predictions\n",
    "y_pred = loaded_model.predict(X_new)\n",
    "\n",
    "# Print results\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
