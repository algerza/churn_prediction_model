{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Import custom functions from utils file\n",
    "from utils import *\n",
    "\n",
    "# Set display options for data exploratory analysis\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('churn_initial_df.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleansing & Outlier detection\n",
    "In this section, we will cover the topic of outliers and data cleansing, as well as inspecting missing values. Outliers are data points that deviate significantly from the rest of the data and can skew analysis, while missing values can introduce bias and inaccuracies in data analysis. We will explore different methods for identifying and handling outliers and missing values, including replacing missing values and clamping outliers. These techniques will help to ensure that our data is clean and reliable for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect the columns, potential null values and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID: ['7590-VHVEG' '5575-GNVDE' '3668-QPYBK' ... '4801-JZAZL' '8361-LTMKD'\n",
      " '3186-AJIEK']\n",
      "gender: ['Female' 'Male']\n",
      "SeniorCitizen: [0 1]\n",
      "Partner: ['Yes' 'No']\n",
      "Dependents: ['No' 'Yes']\n",
      "tenure: [ 1 34  2 45  8 22 10 28 62 13 16 58 49 25 69 52 71 21 12 30 47 72 17 27\n",
      "  5 46 11 70 63 43 15 60 18 66  9  3 31 50 64 56  7 42 35 48 29 65 38 68\n",
      " 32 55 37 36 41  6  4 33 67 23 57 61 14 20 53 40 59 24 44 19 54 51 26  0\n",
      " 39]\n",
      "PhoneService: ['No' 'Yes']\n",
      "MultipleLines: ['No phone service' 'No' 'Yes']\n",
      "InternetService: ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity: ['No' 'Yes' 'No internet service']\n",
      "OnlineBackup: ['Yes' 'No' 'No internet service']\n",
      "DeviceProtection: ['No' 'Yes' 'No internet service']\n",
      "TechSupport: ['No' 'Yes' 'No internet service']\n",
      "StreamingTV: ['No' 'Yes' 'No internet service']\n",
      "StreamingMovies: ['No' 'Yes' 'No internet service']\n",
      "Contract: ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling: ['Yes' 'No']\n",
      "PaymentMethod: ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "MonthlyCharges: [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
      "TotalCharges: ['29.85' '1889.5' '108.15' ... '346.45' '306.6' '6844.5']\n",
      "Churn: ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Print all unique values for each column.\n",
    "#   This will help us inspect strange values in columns.\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"{column}: {unique_values}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct values in column\n",
    "If the column is not properly classified as boolean, it can affect the performance of certain models or analyses that require boolean data. Additionally, it may be misleading to interpret non-boolean columns as boolean, which can lead to incorrect conclusions or actions based on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID                                  object\n",
      "SeniorCitizen                                int64\n",
      "Partner                                      int64\n",
      "Dependents                                   int64\n",
      "tenure                                       int64\n",
      "PhoneService                                 int64\n",
      "MultipleLines                                int64\n",
      "OnlineSecurity                               int64\n",
      "OnlineBackup                                 int64\n",
      "DeviceProtection                             int64\n",
      "TechSupport                                  int64\n",
      "StreamingTV                                  int64\n",
      "StreamingMovies                              int64\n",
      "PaperlessBilling                             int64\n",
      "MonthlyCharges                             float64\n",
      "TotalCharges                               float64\n",
      "Churn                                        int64\n",
      "Has_Internet_Service                         int64\n",
      "gender_Female                                uint8\n",
      "gender_Male                                  uint8\n",
      "Contract_Month-to-month                      uint8\n",
      "Contract_One year                            uint8\n",
      "Contract_Two year                            uint8\n",
      "InternetService_DSL                          uint8\n",
      "InternetService_Fiber optic                  uint8\n",
      "PaymentMethod_Bank transfer (automatic)      uint8\n",
      "PaymentMethod_Credit card (automatic)        uint8\n",
      "PaymentMethod_Electronic check               uint8\n",
      "PaymentMethod_Mailed check                   uint8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# There are some columns that are supposed to have categorical values only,\n",
    "#   but include more. We need to correct them.\n",
    "\n",
    "# replace 'No phone service' with NaN values\n",
    "df['MultipleLines'].replace('No phone service', np.nan, inplace=True)\n",
    "\n",
    "# replace 'No internet service' with NaN values\n",
    "df.replace('No internet service', np.nan, inplace=True)\n",
    "\n",
    "# create a new column 'Has_Internet_Service' which has a value of 1 if any of the columns in a row have a non-NaN value\n",
    "df['Has_Internet_Service'] = df[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']].notnull().any(axis=1).astype(int)\n",
    "\n",
    "# replace 'Yes' with 1 and 'No' with 0\n",
    "df.replace(['Yes', 'No'], [1, 0], inplace=True)\n",
    "\n",
    "# fill NaN values with 0s for the new columns\n",
    "df[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'MultipleLines']] = df[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'MultipleLines']].fillna(0).astype('int64')\n",
    "\n",
    "\n",
    "# Replace Yes, No with 1,0 in all columns where there is\n",
    "#    only Yes, No values\n",
    "\n",
    "# Loop through each column\n",
    "for col in df.columns:\n",
    "    # Check if column has only 'Yes' and 'No' values\n",
    "    if set(df[col].unique()) == set(['Yes', 'No']):\n",
    "        # Replace 'Yes' with 1 and 'No' with 0\n",
    "        df[col] = df[col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "# Define list of columns to convert to numeric\n",
    "cols_to_convert = ['TotalCharges']\n",
    "\n",
    "# Loop through each column and convert to float\n",
    "for col in cols_to_convert:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Convert categorical variables to binary using one-hot encoding\n",
    "#    The resulting dummy variables are added to the DataFrame as new columns\n",
    "df = pd.get_dummies(df, columns=[\"gender\", \"Contract\", \"InternetService\", \"PaymentMethod\"])\n",
    "\n",
    "# Drop the column because it is redundant with Has_Internet_Service column\n",
    "df.drop('InternetService_0', axis=1, inplace=True)\n",
    "\n",
    "# Print data types of all columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify duplicates\n",
    "Duplicate rows can skew summary statistics, such as means and standard deviations, and create biases in machine learning models. They can also cause data redundancy and increase the computational time required to process the data. Therefore, identifying and removing duplicates can improve the quality and reliability of the data used for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- There are no duplicated values in the dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Apply function\n",
    "check_for_duplicates(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "If there are missing values in a dataset, it can impact the statistical power of your analysis, and can even result in incorrect conclusions. Furthermore, many machine learning algorithms require complete data, and missing values can cause errors in these algorithms. Therefore, it is essential to identify and handle missing data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- There are missing values in the dataframe. Column 'TotalCharges' has missing values.\n"
     ]
    }
   ],
   "source": [
    "# Apply function\n",
    "check_for_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the previous output, there are missing values in the column 'TotalCharges'\n",
    "#    Therefore, we have to replace NaN values in TotalCharges with 0s\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(0).astype('int64')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Imbalanced dataset\n",
    "If a dataset is imbalanced, meaning that one class of the target variable is overrepresented compared to the other, the model may learn to predict the majority class more accurately and perform poorly on the minority class. This can result in biased or inaccurate predictions, especially if the minority class is of particular interest. By identifying and addressing class imbalance, such as through resampling techniques or adjusting class weights, a model can be trained to better handle imbalanced data and make more accurate predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The dataframe is imbalanced, with an imbalance ratio of 0.27.\n"
     ]
    }
   ],
   "source": [
    "# Apply function\n",
    "check_for_imbalanced_dataset(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Outliers\n",
    "Flagging outliers in a dataset can be useful in identifying potential errors or anomalies in the data, Additionally, you can use the flags as a feature in your model to improve its accuracy, or use them to create new features that capture the presence of outliers in the data. In this function, outliers are detected by comparing each value to the mean and standard deviation of the column, as well as the 1st and 99th percentiles of the column. The function skips outlier detection for binary columns, and joins the outlier flags DataFrame with the input DataFrame to return a new DataFrame with outlier flags. This function can be useful for identifying and handling outliers before training a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier column created: tenure\n",
      "Outlier column created: MonthlyCharges\n",
      "Outlier column created: TotalCharges\n"
     ]
    }
   ],
   "source": [
    "# Apply function\n",
    "df = flag_outliers(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clamp outliers\n",
    "Clamping outliers in numerical columns can help to improve the overall quality of the data and prevent the model from being biased by the presence of extreme values. By replacing outliers with the nearest in-range values, the distribution of the data becomes more normalized, which can help the model make more accurate predictions. Clamping outliers also helps to avoid the risk of overfitting to the training data, which can happen when the model is trying to learn from extreme and non-representative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to be modified: \n",
      "tenure\n",
      "MonthlyCharges\n",
      "TotalCharges\n",
      "\n",
      "86 customer IDs affected.\n"
     ]
    }
   ],
   "source": [
    "# Apply function\n",
    "df = clamp_outliers(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "It is generally a good practice to scale or normalize your data before using it for model training with XGBoost. The main reason for doing this is to ensure that all features contribute equally to the model and to avoid the domination of certain features over others.\n",
    "\n",
    "For example, if you do not scale or normalize the TotalCharges feature, it may dominate over other features that have smaller values, causing the model to become biased towards it. By scaling or normalizing the features, you can bring them to the same scale and make them equally important for the model.\n",
    "\n",
    "Therefore, it is recommended to scale or normalize your data before using it for model training with XGBoost. There are several methods for scaling or normalization, including StandardScaler, MinMaxScaler, and RobustScaler. You can choose the one that best suits your data and the specific problem you are trying to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the columns to normalize\n",
    "# # cols_to_normalize = ['MonthlyCharges', 'TotalCharges']\n",
    "# cols_to_normalize = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# # Create the MinMaxScaler object\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # Fit and transform the data\n",
    "# df[cols_to_normalize] = scaler.fit_transform(df[cols_to_normalize])\n",
    "\n",
    "# # Check how the column values look after the normalization\n",
    "# df[cols_to_normalize].head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing clean dataframe\n",
    "Store the dataframe after all our operations for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store cleaned df for modelling\n",
    "df.to_csv('churn_cleaned_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a7084dce4a57fabdb294815b03e7954449d6920124286f14e8400459bb21104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
